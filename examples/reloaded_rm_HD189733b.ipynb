{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/vxh710/.matplotlib/stylelib/paper.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/vxh710/.matplotlib/stylelib/presentation.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/vxh710/.matplotlib/stylelib/poster_dark.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/vxh710/.matplotlib/stylelib/paper_twocol.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/vxh710/.matplotlib/stylelib/poster.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/vxh710/.matplotlib/stylelib/presentation_dark.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from astropy.io import fits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/vxh710/PhD/software/elle/elle\")\n",
    "import utils\n",
    "# from utils.io import read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading the CCFs\n",
    "\n",
    "We will start by loading in the cross-correlation functions (CCFs). This step will be similar for data from e.g. HARPS, HARPS-N, SOPHIE, CORALIE, and ESPRESSO since their pipelines compute the CCFs. For other spectrographs where this may not the case, a CCF will first have to be computed. This is outside the scope of this tutorial.\n",
    "\n",
    "Once the data is read we will do a number of adjustments. \n",
    "\n",
    "*i)* The velocity step size in the HARPS data product we are using is 0.25 km/s, which is *oversampled*. We will only keep every one out of four points, which will more closely resemble the natural resolution of HARPS. \n",
    "\n",
    "*ii)* For this particular data the CCF covers a wide range of the continuum. The continuum is not as important to us as the line core itself, so we are going to mask out most of the continuum with a mask `m`, which will simplify things later.\n",
    "\n",
    "*iii)* One can also notice that the velocity grids (the first reference to `rv` below) from all the observations line up, i.e. have the same reference value and step size. For now, we are going to assume that the radial velocity grids are aligned (as in this case), which means we do not have to store the velocity array for each individual CCF. In this case, we let `rv` be the common grid for all the CCFs.\n",
    "\n",
    "**Note**: The velocity grids are not necessarily always aligned, depending on the data reduction. If they are not aligned, it will simplify things later on if we first align them. If only the reference value is different for some CCFs but they have the same step size and most of the grids align, then the simplest solution is to discard the data that are outside of the common range for all of them. If most of the grid does not align, a solution may be to resample the CCFs (see later), or let `rv` be a list for the remainder of the tutorial so that each CCF has its own unique velocity grid. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/vxh710/PhD/projects/reloaded/data/HD189733/fits/2006-09-08\"\n",
    "\n",
    "# save the full path to each FITS file in a list (exclude .DS_Store files on MacOS)\n",
    "files = [os.path.join(data_dir, x) for x in os.listdir(data_dir) if not x.startswith('.')]\n",
    "\n",
    "files.sort() # files read are not necessarily in order, so order by timestamp in filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from astropy.io import fits\n",
    "\n",
    "# f = fits.open('/Users/vxh710/PhD/projects/reloaded/data/HD189733/fits/2006-09-08/HARPS.2006-09-08T01:19:45.782_ccf_K5_A.fits')\n",
    "# f[0].header\n",
    "\n",
    "# HIERARCH ESO DRS CCF RVC = -2.16965003456311 / Baryc RV (drift corrected) (km/s)\n",
    "# HIERARCH ESO DRS CCF CONTRAST = 39.9438996989951 / Contrast of  CCF (%)         \n",
    "# HIERARCH ESO DRS CCF FWHM = 7.52428638475369 / FWHM of CCF (km/s)               \n",
    "# HIERARCH ESO DRS CCF RV = -2.16965003456311\n",
    "# HIERARCH ESO DRS BJD\n",
    "# EXPTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv, ccf, obs = utils.io.read(files, oversample=4)\n",
    "\n",
    "rv = np.median(rv, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-252., -251., -250., -249., -248., -247., -246., -245., -244.,\n",
       "       -243., -242., -241., -240., -239., -238., -237., -236., -235.,\n",
       "       -234., -233., -232., -231., -230., -229., -228., -227., -226.,\n",
       "       -225., -224., -223., -222., -221., -220., -219., -218., -217.,\n",
       "       -216., -215., -214., -213., -212., -211., -210., -209., -208.,\n",
       "       -207., -206., -205., -204., -203., -202., -201., -200., -199.,\n",
       "       -198., -197., -196., -195., -194., -193., -192., -191., -190.,\n",
       "       -189., -188., -187., -186., -185., -184., -183., -182., -181.,\n",
       "       -180., -179., -178., -177., -176., -175., -174., -173., -172.,\n",
       "       -171., -170., -169., -168., -167., -166., -165., -164., -163.,\n",
       "       -162., -161., -160., -159., -158., -157., -156., -155., -154.,\n",
       "       -153., -152., -151., -150., -149., -148., -147., -146., -145.,\n",
       "       -144., -143., -142., -141., -140., -139., -138., -137., -136.,\n",
       "       -135., -134., -133., -132., -131., -130., -129., -128., -127.,\n",
       "       -126., -125., -124., -123., -122., -121., -120., -119., -118.,\n",
       "       -117., -116., -115., -114., -113., -112., -111., -110., -109.,\n",
       "       -108., -107., -106., -105., -104., -103., -102., -101., -100.,\n",
       "        -99.,  -98.,  -97.,  -96.,  -95.,  -94.,  -93.,  -92.,  -91.,\n",
       "        -90.,  -89.,  -88.,  -87.,  -86.,  -85.,  -84.,  -83.,  -82.,\n",
       "        -81.,  -80.,  -79.,  -78.,  -77.,  -76.,  -75.,  -74.,  -73.,\n",
       "        -72.,  -71.,  -70.,  -69.,  -68.,  -67.,  -66.,  -65.,  -64.,\n",
       "        -63.,  -62.,  -61.,  -60.,  -59.,  -58.,  -57.,  -56.,  -55.,\n",
       "        -54.,  -53.,  -52.,  -51.,  -50.,  -49.,  -48.,  -47.,  -46.,\n",
       "        -45.,  -44.,  -43.,  -42.,  -41.,  -40.,  -39.,  -38.,  -37.,\n",
       "        -36.,  -35.,  -34.,  -33.,  -32.,  -31.,  -30.,  -29.,  -28.,\n",
       "        -27.,  -26.,  -25.,  -24.,  -23.,  -22.,  -21.,  -20.,  -19.,\n",
       "        -18.,  -17.,  -16.,  -15.,  -14.,  -13.,  -12.,  -11.,  -10.,\n",
       "         -9.,   -8.,   -7.,   -6.,   -5.,   -4.,   -3.,   -2.,   -1.,\n",
       "          0.,    1.,    2.,    3.,    4.,    5.,    6.,    7.,    8.,\n",
       "          9.,   10.,   11.,   12.,   13.,   14.,   15.,   16.,   17.,\n",
       "         18.,   19.,   20.,   21.,   22.,   23.,   24.,   25.,   26.,\n",
       "         27.,   28.,   29.,   30.,   31.,   32.,   33.,   34.,   35.,\n",
       "         36.,   37.,   38.,   39.,   40.,   41.,   42.,   43.,   44.,\n",
       "         45.,   46.,   47.,   48.,   49.,   50.,   51.,   52.,   53.,\n",
       "         54.,   55.,   56.,   57.,   58.,   59.,   60.,   61.,   62.,\n",
       "         63.,   64.,   65.,   66.,   67.,   68.,   69.,   70.,   71.,\n",
       "         72.,   73.,   74.,   75.,   76.,   77.,   78.,   79.,   80.,\n",
       "         81.,   82.,   83.,   84.,   85.,   86.,   87.,   88.,   89.,\n",
       "         90.,   91.,   92.,   93.,   94.,   95.,   96.,   97.,   98.,\n",
       "         99.,  100.,  101.,  102.,  103.,  104.,  105.,  106.,  107.,\n",
       "        108.,  109.,  110.,  111.,  112.,  113.,  114.,  115.,  116.,\n",
       "        117.,  118.,  119.,  120.,  121.,  122.,  123.,  124.,  125.,\n",
       "        126.,  127.,  128.,  129.,  130.,  131.,  132.,  133.,  134.,\n",
       "        135.,  136.,  137.,  138.,  139.,  140.,  141.,  142.,  143.,\n",
       "        144.,  145.,  146.,  147.,  148.,  149.,  150.,  151.,  152.,\n",
       "        153.,  154.,  155.,  156.,  157.,  158.,  159.,  160.,  161.,\n",
       "        162.,  163.,  164.,  165.,  166.,  167.,  168.,  169.,  170.,\n",
       "        171.,  172.,  173.,  174.,  175.,  176.,  177.,  178.,  179.,\n",
       "        180.,  181.,  182.,  183.,  184.,  185.,  186.,  187.,  188.,\n",
       "        189.,  190.,  191.,  192.,  193.,  194.,  195.,  196.,  197.,\n",
       "        198.,  199.,  200.,  201.,  202.,  203.,  204.,  205.,  206.,\n",
       "        207.,  208.,  209.,  210.,  211.,  212.,  213.,  214.,  215.,\n",
       "        216.,  217.,  218.,  219.,  220.,  221.,  222.,  223.,  224.,\n",
       "        225.,  226.,  227.,  228.,  229.,  230.,  231.,  232.,  233.,\n",
       "        234.,  235.,  236.,  237.,  238.,  239.,  240.,  241.,  242.,\n",
       "        243.,  244.,  245.,  246.,  247.,  248.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97b11a5f21a474685ad3ed5a4afbe9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = (rv < (np.median(obs['rv']) - 1.5 * np.median(obs['fwhm']))) | (rv > (np.median(obs['rv']) + 1.5 * np.median(obs['fwhm'])))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "ax[0].plot(rv, ccf[0])\n",
    "ax[0].plot(rv[m], ccf[0][m], '.C1', label='continuum')\n",
    "ax[0].set_xlabel('velocity (km/s)')\n",
    "ax[0].set_ylabel('ccf flux')\n",
    "ax[0].set_title('not normalized')\n",
    "ax[0].legend()\n",
    "\n",
    "# normalize by continuum\n",
    "ccf /= np.median(ccf[:,m], axis=1)[:,None] # estimate continuum\n",
    "\n",
    "ax[1].plot(rv, ccf[0])\n",
    "ax[1].set_xlabel('velocity (km/s)')\n",
    "ax[1].set_ylabel('ccf flux')\n",
    "ax[1].set_title('normalized by continuum');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c3f87f7fb74f539f2c6370560e8217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the timestamps of the observations\n",
    "time = np.array([fits.getval(x, 'HIERARCH ESO DRS BJD') for x in files])\n",
    "\n",
    "# the CCFs are given per order, and we are interested in the last element which is the combined CCF from all orders\n",
    "ccf = [fits.getdata(x)[-1,:] for x in files]\n",
    "\n",
    "# next, we create the radial velocity grid - Note: the headers may differ between instruments\n",
    "start = [fits.getval(x, 'CRVAL1') for x in files] # the velocity at the first (reference) pixel\n",
    "step = [fits.getval(x, 'CDELT1') for x in files] # the velocity step size\n",
    "rv = [np.arange(start[i], start[i] + len(ccf[i]) * step[i], step[i]) for i in range(len(ccf))]\n",
    "\n",
    "# if velocity grids are the same for all CCFs we use a common velocity grid\n",
    "# NOTE: verify that this is true for your data\n",
    "rv = rv[0] \n",
    "\n",
    "# create mask to remove most of continuum\n",
    "rv_min = rv[np.argmin(ccf[0])] # approximate velocity of CCF line centre\n",
    "m = (rv > (rv_min - 40)) & (rv < (rv_min + 40)) # can use same mask since RV doesn't change much during sequence\n",
    "\n",
    "# discard oversampled points\n",
    "rv = rv[m][::4]\n",
    "ccf = np.atleast_2d(ccf)[:,m][:,::4] # note that the velocity grids should be the same for all CCFs in order to cast the CCF list into a 2d array\n",
    "\n",
    "# normalize the CCFs by continuum using the computed line centres and widths\n",
    "rvc = np.array([fits.getval(x, 'HIERARCH ESO DRS CCF RVC') for x in files])\n",
    "rvc_err = np.array([fits.getval(x, 'HIERARCH ESO DRS CCF NOISE') for x in files])\n",
    "# line_centre = np.median([fits.getval(x, 'HIERARCH ESO DRS CCF RVC') for x in files])\n",
    "line_width = np.median([fits.getval(x, 'HIERARCH ESO DRS CCF FWHM') for x in files])\n",
    "\n",
    "# select continuum by some distance from line centre\n",
    "# Note: variable name has no relation to previous mask, which we also called `m`\n",
    "m = (rv < (np.median(rvc) - 1.5 * line_width)) | (rv > (np.median(rvc) + 1.5 * line_width))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "ax[0].plot(rv, ccf[0])\n",
    "ax[0].plot(rv[m], ccf[0][m], '.C1', label='continuum')\n",
    "ax[0].set_xlabel('velocity (km/s)')\n",
    "ax[0].set_ylabel('ccf flux')\n",
    "ax[0].set_title('not normalized')\n",
    "ax[0].legend()\n",
    "\n",
    "# normalize by continuum\n",
    "ccf /= np.median(ccf[:,m], axis=1)[:,None] # estimate continuum\n",
    "\n",
    "ax[1].plot(rv, ccf[0])\n",
    "ax[1].set_xlabel('velocity (km/s)')\n",
    "ax[1].set_ylabel('ccf flux')\n",
    "ax[1].set_title('normalized by continuum');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# rv_min = rv[np.argmin(ccf[0])] # approximate velocity of CCF line centre\n",
    "# m = (rv > (rv_min - 40)) & (rv < (rv_min + 40))\n",
    "\n",
    "# ncols = 3\n",
    "# nrows = int(len(ccf) / ncols) + 1\n",
    "\n",
    "# fig, axes = plt.subplots(nrows, ncols, figsize=(10, nrows*3))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i in range(len(ccf)):\n",
    "#     axes[i].plot(rv[m], ccf[i][m])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Light curve normalization and Keplerian correction\n",
    "\n",
    "The CCF flux is not normalized by reference stars, so we will have to normalize them manually to account for the loss of light during transit. We will also have to resample the CCFs onto a new grid to correct for the Keplerian slope of the star due to the planet at the time of observations.\n",
    "\n",
    "For this, we will need to compute a transit model and radial velocity curve using some pre-existing software package. In this tutorial we will use `exoplanet`, but really any software that can compute transit light curves and radial velocity curves will do. \n",
    "\n",
    "First, we will define some planetary and orbital parameters for the light curve and radial velocity models, and calculate the phases and duration of the transit which will be important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/vxh710/PhD/software/elle\")\n",
    "from utils import\n",
    "\n",
    "# dur    = 1.827/24                       # duration between first and fourth transit contact (days)\n",
    "ror    = 0.15667                        # planet-star radius ratio\n",
    "period = 2.21857567                     # orbital period (days)\n",
    "t0     = 2454279.436714                 # transit time (BJD)\n",
    "K      = 200.56                         # RV semi-amplitude (m/s)\n",
    "incl   = 85.710                         # orbital inclination (deg)\n",
    "aor    = 8.863                          # scaled separation\n",
    "roa    = 1/aor\n",
    "b      = np.cos(np.deg2rad(incl)) * aor # impact parameter\n",
    "\n",
    "u      = np.array([0.816, 0])           # limb darkening coefficients for quadratic law\n",
    "\n",
    "\n",
    "# get orbital phase of observations\n",
    "phase = (time - t0) % period / period\n",
    "phase[phase > 0.5] -= 1\n",
    "\n",
    "\n",
    "# compute transit duration between contacts\n",
    "dur14 = utils.get_14_transit_duration(period, 1/aor, ror, b, np.deg2rad(incl))\n",
    "dur23 = utils.get_23_transit_duration(period, 1/aor, ror, b, np.deg2rad(incl))\n",
    "\n",
    "# create masks to easily select points in/out of transit\n",
    "m14 = utils.get_transit_mask(phase, dur14/period)\n",
    "m23 = utils.get_transit_mask(phase, dur23/period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the transit light curve and radial velocity (Keplerian slope only, *without* Rossiter-McLaughlin model). Here we use `exoplanet`, but any other code will do. What we're interested in are the light curve and radial velocity slope at the times of our observations, so if you can compute that using another code and save those in arrays called `lcmod` and `rvmod`, then the rest of the tutorial should still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5ab9da400544a0ae369fe53afab09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import exoplanet as xo\n",
    "\n",
    "# the `duration` parameter in `exoplanet` refers to the interval between the halfway points of ingress and egress,\n",
    "# i.e. contact times 1.5 and 3.5\n",
    "dur_xo = dur14 - 0.5 * (dur14 - dur23)\n",
    "# dur_xo = period / (np.pi * aor) * np.sqrt(1 - b**2) # Winn 2010, Transits and Occultations\n",
    "\n",
    "# exposure time of RV observations to correct for finite integration time\n",
    "texp = np.array([fits.getval(x, 'EXPTIME') for x in files]) / 60 / 60 / 24 \n",
    "\n",
    "orbit = xo.orbits.KeplerianOrbit(\n",
    "           duration=dur_xo,\n",
    "           period=period,\n",
    "           t0=t0,\n",
    "           b=b\n",
    "        )\n",
    "\n",
    "def get_lc(x):\n",
    "    return np.sum(\n",
    "                (\n",
    "                xo.LimbDarkLightCurve(u).get_light_curve(\n",
    "                    orbit=orbit, r=ror, t=x, texp=np.median(texp)/60/60/24\n",
    "                    )\n",
    "                ).eval(), axis=-1) + 1\n",
    "\n",
    "def get_rv(x):\n",
    "    return orbit.get_radial_velocity(x, K=K).eval() / 1e3\n",
    "\n",
    "\n",
    "# model at timestamps: compute these using another code if `exoplanet` is not installed on your system\n",
    "lcmod = get_lc(time)\n",
    "rvmod = get_rv(time)\n",
    "\n",
    "# finer models for visualization\n",
    "time_f  = np.linspace(time[0], time[-1], 200)\n",
    "phase_f = np.linspace(phase.min(), phase.max(), 200)\n",
    "lcmod_f = get_lc(time_f)\n",
    "rvmod_f = get_rv(time_f)\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True, figsize=(6,6), gridspec_kw={\"hspace\":0.03})\n",
    "\n",
    "# estimate systemic velocity from out-of-transit observations for visualization.\n",
    "# this will fail if there are no data outside transit\n",
    "vsys = np.average((rvc - rvmod)[~m14], weights=rvc_err[~m14])\n",
    "\n",
    "axes[0].plot(phase_f*period, rvmod_f*1e3, label='model')\n",
    "# axes[0].plot(phase*period, rvmod, '.', label=\"timestamps\")\n",
    "axes[0].errorbar(phase*period, (rvc - vsys)*1e3, yerr=rvc_err*1e3, capsize=0, fmt='.', label=\"data\")\n",
    "axes[0].set_ylabel('RV (km/s)')\n",
    "\n",
    "axes[1].plot(phase_f*period, lcmod_f, label='model')\n",
    "axes[1].plot(phase*period, lcmod, '.', label=\"timestamps\")\n",
    "axes[1].set_ylabel('normalised flux')\n",
    "\n",
    "\n",
    "axes[2].errorbar(phase*period, (rvc - rvmod - vsys)*1e3, yerr=rvc_err*1e3, capsize=0, fmt='.', label=\"RM data\\nwithout slope\")\n",
    "axes[2].set_ylabel('RV (m/s)')\n",
    "axes[2].set_xlabel('phase (d)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axvline(-0.5 * dur14, c=\"#aaaaaa\")\n",
    "    ax.axvline(0.5 * dur14, c=\"#aaaaaa\")\n",
    "    ax.axvline(-0.5 * dur23, ls='dashed', c=\"#aaaaaa\")\n",
    "    ax.axvline(0.5 * dur23, ls='dashed', c=\"#aaaaaa\")\n",
    "    ax.axvline(0, ls='dotted', c='#aaaaaa')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! We can see that our model for the Keplerian slope has been removed from the bottom panel. Now that we know our model is good, we can correct the CCFs for the slope by resampling them onto a new grid. We will here also normalize our CCFs by the transit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_lcnorm = utils.normalise_ccf(ccf, lcmod)#, err=ccf_err)\n",
    "ccf_lcnorm += (1 - lcmod[:,None])\n",
    "\n",
    "# we remove the first and last pixels since the interpolation may introduce weird spikes in the CCF\n",
    "ccf_resampled = utils.resample2(np.tile(rv, (len(ccf_lcnorm), 1)), ccf_lcnorm, rvmod)[:,1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create the master out of transit reference and residual CCFs\n",
    "\n",
    "The reloaded Rossiter-McLaughlin approach aims at isolating the distortion of the CCF due to the planet transit. In order to do this, we will need to create a high SNR CCF profile based on our out of transit data, `master_ccf_out`. Because the CCFs have been resampled to correct for the Keplerian motion, they are in the system's barycentric reference frame so that their line centres are aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809fbcd9d97a4324b1b0d2abc7115c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'flux')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create master ccf by averaging out of transit observations\n",
    "master_ccf_out = np.mean(ccf_resampled[~m14], axis=0)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rv[1:-1], master_ccf_out, lw=1, c='k')\n",
    "for i in range(len(ccf_resampled)):\n",
    "    plt.plot(rv[1:-1], ccf_resampled[i], lw=0.5)\n",
    "plt.xlabel('velocity (km/s)')\n",
    "plt.ylabel('flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the plot, all the CCFs are still centered on the systemic velocity, although the Doppler reflex motion due to the planet has been removed. To correct for this, we compute the line centre of `master_ccf_out` from a least-squares fit and correct our velocity grid for this to bring it to the stellar rest frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radial velocity of line centre is -2226.88 +- 0.20 m/s\n"
     ]
    }
   ],
   "source": [
    "ccf_residual = master_ccf_out - ccf_resampled\n",
    "\n",
    "# we estimate the photon noise on each CCF by calculating the spread in flux at each pixel for the out of transit CCFs\n",
    "ccf_err = np.std(ccf_residual[~m14], axis=0)\n",
    "\n",
    "# the error on the master CCF will be reduced by sqrt(n)\n",
    "master_ccf_out_err = ccf_err / np.sqrt(np.count_nonzero(~m14))\n",
    "\n",
    "# fit Gaussian to master out of transit CCF with least-squares minimization\n",
    "popt, perr = utils.fit_ccf(rv[1:-1], master_ccf_out, yerr=master_ccf_out_err)\n",
    "\n",
    "print(f\"radial velocity of line centre is {popt[2]*1e3:.2f} +- {perr[2]*1e3:.2f} m/s\")\n",
    "\n",
    "# remove systemic velocity to bring CCFs into the stellar rest frame\n",
    "master_rv = rv[1:-1] - popt[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have successfully isolated the planet shadow, where `ccf_residual` represents the light from the regions on the star that are occulted by the planet due to the transit. The line centres `ccf_residual` represent the surface radial velocity on the star at each transit epoch. We can plot these profiles and their characteristic *trace* below, showing that the regions on the star that the planet occulted is moving from negative to positive surface velocities, indicative of a prograde orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732fbfafbb38414caa440070e35e0c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = utils.plot_trace(phase, master_rv, ccf_residual, m14,\n",
    "                       duration_14=dur14/period, # these arguments are supplied so that we can draw lines at the expected ingress/egress\n",
    "                       duration_23=dur23/period,\n",
    "                       period=period,\n",
    "                       show_legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieving local stellar surface velocities\n",
    "\n",
    "We will now retrieve the surface radial velocities on the star. In this step we will assume that the residual CCFs have a Gaussian shape, as the asymmetry due to convective blueshift has been subtracted off using `master_ccf_out`. If your residual line profiles are not simple Gaussians, then you can here also experiment with other functional forms (e.g. double Gaussian for M dwarfs, Bourrier et al. 2018). What is important is that all residual CCFs should be fitted with the same model.\n",
    "\n",
    "In this tutorial we will use a simple least-squares fit to the residual line profiles because this is the fastest, however `elle` also has support for MCMC using `pymc3` for more in-depth analysis of any correlation between parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, perr = utils.fit_ccf_residuals(master_rv, ccf_residual[m14], err=ccf_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e052c3daf8c4209be537a0169cd45a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ncols = 3\n",
    "nrows = int(len(ccf_residual[m14]) / ncols) + 1\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(8, nrows*3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "x = np.linspace(master_rv.min(), master_rv.max(), 200)\n",
    "unit = 1e3 # ppt\n",
    "# for i in range(len(ccf_residual[m14])):\n",
    "for i in range(len(axes)):\n",
    "    if i >= len(ccf_residual[m14]):\n",
    "        axes[i].axis('off')\n",
    "        continue\n",
    "    axes[i].plot(x, utils.inverted_normal_distribution(x, *popt[i])*unit)\n",
    "    axes[i].errorbar(master_rv, ccf_residual[m14][i]*unit, yerr=ccf_err*unit, capsize=0, fmt='none', c='k')\n",
    "    \n",
    "    axes[i].set_xlabel('RV (km/s)')\n",
    "    axes[i].set_ylabel('flux (ppt)')\n",
    "  \n",
    "fig.tight_layout()\n",
    "# models = np.atleast_2d([utils.inverted_normal_distribution(master_rv, *popt[i])\n",
    "#                         for i in range(len(popt))])\n",
    "# # print(models)\n",
    "# fig = utils.plot_ccfs(np.ones_like(ccf_residual[m23]) * master_rv,\n",
    "#                 ccf_residual[m23],\n",
    "#                 ccf_err=np.ones_like(ccf_residual[m23]) * ccf_err,\n",
    "#                      model=models);\n",
    "# axes = fig.axes\n",
    "# for i in range(len(axes)):\n",
    "#     axes[i].plot(x, utils.inverted_normal_distribution(x, *popt[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.618615   2.70307078 2.77112235 2.67580732 2.66974917 2.69457073\n",
      " 2.76706525 2.71161125 2.49857269]\n"
     ]
    }
   ],
   "source": [
    "_, depth, centre, width = popt.T[:,1:-1]\n",
    "_, depth_err, centre_err, width_err = perr.T[:,1:-1]\n",
    "phase_in = phase[m14][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f6d0ffb913474e991e60307b3133a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.16636709 6.36524526 6.52549445 6.30104472 6.28677885 6.34522918\n",
      " 6.51594071 6.38535652 5.88368906]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'local FWHM (km/s)')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(6,6), gridspec_kw={'hspace':0.02})\n",
    "\n",
    "fwhm = 2 * np.sqrt(2 * np.log(2)) * width\n",
    "fwhm_err = 2 * np.sqrt(2 * np.log(2)) * width_err\n",
    "\n",
    "axes[0].errorbar(phase_in, centre, yerr=centre_err, capsize=0, fmt='.')\n",
    "axes[0].tick_params(labelbottom=False)\n",
    "axes[0].set_ylabel('local RV (km/s)')\n",
    "\n",
    "axes[1].errorbar(phase_in, depth*unit, yerr=depth_err*unit, capsize=0, fmt='.')\n",
    "axes[1].tick_params(labelbottom=False)\n",
    "axes[1].set_ylabel('local contrast (ppt)')\n",
    "\n",
    "axes[2].errorbar(phase_in, fwhm, yerr=fwhm_err, capsize=0, fmt='.')\n",
    "axes[2].set_xlabel('phase')\n",
    "axes[2].set_ylabel('local FWHM (km/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [06:18<00:00, 26.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import emcee\n",
    "sys.path.append(\"/Users/vxh710/PhD/software/elle\")\n",
    "import model\n",
    "\n",
    "\n",
    "threads = 2\n",
    "walkers = 100\n",
    "steps = 10000\n",
    "\n",
    "istar = 90. # stellar inclination, i.e. fitting for vsini, and not v_eq\n",
    "alpha = 0. # assume rigid body, no differential rotation\n",
    "\n",
    "bounds = (-20, 20)\n",
    "\n",
    "reloaded_kwargs = {'r_1':roa, 'i_p':incl, 'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "\n",
    "relo = model.ReloadedModel(phase_in, **reloaded_kwargs)\n",
    "\n",
    "def _log_prior(theta):\n",
    "        \n",
    "    vs, vc = theta\n",
    "    \n",
    "    if vs < bounds[0] or vs > bounds[1]:\n",
    "        return -np.inf\n",
    "    elif vc < bounds[0] or vc > bounds[1]:\n",
    "        return -np.inf\n",
    "\n",
    "    return 0\n",
    "\n",
    "def _log_likelihood(data, model, error):\n",
    "        inv_sigma2 = 1/error**2\n",
    "        return -0.5 * np.sum((data - model)**2 * inv_sigma2 - np.log(inv_sigma2))\n",
    "\n",
    "def _log_probability(theta):\n",
    "\n",
    "    # calculate prior and check the new parameters are within bounds\n",
    "    l = _log_prior(theta)\n",
    "    \n",
    "    if not np.isfinite(l):\n",
    "        return -np.inf\n",
    "    \n",
    "    # calculate vsini and lambda from the free parameters\n",
    "    vs, vc = theta # vs = sqrt(vsini) * np.sin(lambda); vc = sqrt(vsini) * np.cos(lambda)\n",
    "    vsini = vs**2 + vc**2  \n",
    "    ell = np.rad2deg(np.arctan2(vs, vc))\n",
    "\n",
    "    mod = relo(vsini, ell, istar, alpha) # calculate surface RV model\n",
    "\n",
    "    l += _log_likelihood(centre, mod, centre_err)\n",
    "    \n",
    "    return l\n",
    "\n",
    "parameters = ['vs', 'vc']\n",
    "ndim = len(parameters)\n",
    "\n",
    "init = []\n",
    "for i in range(walkers):\n",
    "    pos = np.random.uniform(*bounds, 2)\n",
    "    \n",
    "    # check that the initial positions are within prior bounds to be safe\n",
    "    while not np.isfinite(_log_prior(pos)):\n",
    "        pos = np.random.uniform(*bounds, 2)\n",
    "\n",
    "    init.append(pos)\n",
    "\n",
    "    \n",
    "if threads > 1:\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    with Pool(processes=threads) as pool:\n",
    "        sampler = emcee.EnsembleSampler(walkers, ndim,\n",
    "                                        _log_probability,\n",
    "                                        pool=pool)\n",
    "#                                         args=(phase, rv, rv_err))\n",
    "        sampler.run_mcmc(init, steps, progress=True)\n",
    "else:\n",
    "    sampler = emcee.EnsembleSampler(walkers, ndim,\n",
    "                                        _log_probability)\n",
    "#                                         args=(phase, rv, rv_err))\n",
    "    sampler.run_mcmc(init, steps, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [07:16<00:00, 11.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# # utils.run_mcmc()\n",
    "\n",
    "# # elle.run_mcmc(x, y, yerr, model_kwargs, )\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "# import emcee\n",
    "# sys.path.append(\"/Users/vxh710/PhD/software/elle\")\n",
    "# import model\n",
    "\n",
    "\n",
    "# threads = 2\n",
    "# walkers = 200\n",
    "# steps = 5000\n",
    "\n",
    "\n",
    "# istar = 90.\n",
    "# alpha = 0.\n",
    "\n",
    "# # roa_err = 0.020\n",
    "# roa_err = 0.00025\n",
    "# incl_err = 0.024\n",
    "# ror_err = 0.00012\n",
    "# # m = np.ones_like(centre, dtype=bool)\n",
    "\n",
    "# phase_in = phase[m23]\n",
    "\n",
    "# reloaded_kwargs = {'r_1':roa, 'i_p':incl, 'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "\n",
    "# relo = model.ReloadedModel(phase_in, **reloaded_kwargs)\n",
    "\n",
    "# def _log_prior(theta):\n",
    "    \n",
    "    \n",
    "# #     vsini, ell = theta\n",
    "#     vsini, ell, roa_step, cosi_step = theta\n",
    "#     b_step  = cosi_step / roa_step\n",
    "    \n",
    "#     if vsini < 0.0 or vsini > 20.0:\n",
    "#         return -np.inf\n",
    "#     elif ell < -180.0 or ell > 180.0:\n",
    "#         return -np.inf\n",
    "#     elif cosi_step < 0 or cosi_step > 0.1:\n",
    "#         return -np.inf\n",
    "#     elif roa_step < 0 or roa_step > 1:\n",
    "#         return -np.inf\n",
    "# #     elif ror_step < 0 or ror_step > 1:\n",
    "# #         return -np.inf\n",
    "#     elif b_step < 0 or b_step > 1: # really b_step < 1 + ror, but we know the planet transt is not grazing\n",
    "#         return -np.inf\n",
    "    \n",
    "#     incl_step = np.rad2deg(np.arccos(cosi_step))\n",
    "    \n",
    "#     l = 0\n",
    "#     l += -0.5 * ((incl_step - incl)**2 / incl_err**2)\n",
    "#     l += -0.5 * ((roa_step - roa)**2 / roa_err**2)\n",
    "# #     l += -0.5 * ((ror_step - ror)**2 / ror_err**2)\n",
    "    \n",
    "#     return l\n",
    "\n",
    "# def _log_likelihood(data, model, error):\n",
    "#         inv_sigma2 = 1/error**2\n",
    "#         return -0.5 * np.sum((data - model)**2 * inv_sigma2 - np.log(inv_sigma2))\n",
    "\n",
    "# def _log_probability(theta):\n",
    "\n",
    "#     l = _log_prior(theta)\n",
    "#     if not np.isfinite(l):\n",
    "#         return -np.inf\n",
    "    \n",
    "# #     vsini, ell = theta\n",
    "#     vsini, ell, roa_step, cosi_step = theta\n",
    "    \n",
    "#     incl_step = np.rad2deg(np.arccos(cosi_step))\n",
    "#     b_step  = cosi_step / roa_step\n",
    "    \n",
    "#     dur23 = utils.get_23_transit_duration(period, roa_step, ror, b_step, np.deg2rad(incl_step))\n",
    "# #     dur14 = utils.get_14_transit_duration(period, roa, ror, b, np.deg2rad(incl_step))\n",
    "#     m = utils.get_transit_mask(phase_in, dur23/period)\n",
    "# #     if np.count_nonzero(m) < len(phase_in):\n",
    "# #         return -np.inf\n",
    "    \n",
    "#     if not np.any(m):\n",
    "#         return -np.inf\n",
    "\n",
    "#     reloaded_kwargs = {'r_1':roa_step, 'i_p':incl_step, 'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "#     relo = model.ReloadedModel(phase_in[m], **reloaded_kwargs)\n",
    "#     mod = relo(vsini, ell, istar, alpha)\n",
    "# #     print(mod)\n",
    "# #     print(centre[m])\n",
    "# #     print(len(centre[m]))\n",
    "#     l += _log_likelihood(centre[m], mod, centre_err[m])\n",
    "# #     l += _log_likelihood(centre, mod, centre_err)\n",
    "# #     print(l)\n",
    "#     if not np.isfinite(l):\n",
    "#         print(l, vsini, ell, roa, b, np.any(~m))\n",
    "#         return -np.inf\n",
    "#     return l\n",
    "\n",
    "# parameters = ['vsini', 'ell', 'roa', 'cosi']\n",
    "# ndim = len(parameters)\n",
    "\n",
    "# start = np.array([5, 0, roa, np.cos(np.deg2rad(incl))])\n",
    "# error = np.array([2, 45, roa_err, 0.0001])\n",
    "\n",
    "# init = []\n",
    "# for i in range(walkers):\n",
    "#     pos = start + error * np.random.randn(ndim)\n",
    "#     while not np.isfinite(_log_prior(pos)):\n",
    "#         pos = start + error * np.random.randn(ndim)\n",
    "\n",
    "#     init.append(pos)\n",
    "\n",
    "# if threads > 1:\n",
    "#     os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "#     with Pool(processes=threads) as pool:\n",
    "#         sampler = emcee.EnsembleSampler(walkers, ndim,\n",
    "#                                         _log_probability,\n",
    "#                                         pool=pool)\n",
    "# #                                         args=(phase, rv, rv_err))\n",
    "#         sampler.run_mcmc(init, steps, progress=True)\n",
    "# else:\n",
    "#     sampler = emcee.EnsembleSampler(walkers, ndim,\n",
    "#                                         _log_probability)\n",
    "# #                                         args=(phase, rv, rv_err))\n",
    "#     sampler.run_mcmc(init, steps, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7722b6009adf40d6a1dbb935ca9e4f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discard = int(0.5 * steps)\n",
    "thin = int(np.mean(sampler.get_autocorr_time(discard=discard)))\n",
    "\n",
    "stepsarr = np.arange(int((steps-discard)/thin))\n",
    "\n",
    "fig, axes = plt.subplots(ndim+1,1, figsize=(10,2*ndim),\n",
    "        gridspec_kw={\"hspace\":0.04})\n",
    "\n",
    "\n",
    "vsini = np.sum(sampler.get_chain(discard=discard, thin=thin)**2, axis=-1)\n",
    "ell = np.rad2deg(np.arctan2(*np.rollaxis(sampler.get_chain(discard=discard, thin=thin), 2, 0)))\n",
    "posterior_3d = np.dstack((vsini, ell))\n",
    "\n",
    "\n",
    "labels = ['logp', '$v\\sin{i}$ (km/s)', '$\\lambda$ (deg)']\n",
    "\n",
    "for i in range(ndim+1):\n",
    "    axes[i].set_xlim(0, stepsarr.max())\n",
    "    for j in range(walkers):\n",
    "        if i == 0:\n",
    "            axes[i].plot(stepsarr, sampler.get_log_prob(discard=discard, thin=thin)[:,j], lw=0.5)\n",
    "        else:\n",
    "            axes[i].plot(stepsarr, posterior_3d[:,j,i-1], lw=0.5)\n",
    "        axes[i].set_ylabel(labels[i])\n",
    "        if i == ndim:\n",
    "            axes[i].set_xlabel('steps')\n",
    "        else:\n",
    "            axes[i].tick_params(labelbottom=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8db084cb91420b90620254f8440f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import corner\n",
    "\n",
    "labels = [\"$v\\sin{i}$ (km/s)\", \"$\\lambda$ (deg)\"]\n",
    "\n",
    "posterior_2d = posterior_3d.reshape((-1, posterior_3d.shape[-1]))\n",
    "\n",
    "fig = corner.corner(\n",
    "    posterior_2d,\n",
    "             labels=labels, show_titles=True, title_fmt=\".4f\", bins=30)#,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roa_prior = np.random.normal(roa, roa_err, sampler.get_chain(flat=True, discard=discard, thin=thin).shape[0])\n",
    "# cosi_prior = np.cos(\n",
    "#                     np.deg2rad(\n",
    "#                             np.random.normal(\n",
    "#                                     incl, incl_err, sampler.get_chain(flat=True, discard=discard, thin=thin).shape[0]\n",
    "#                             )\n",
    "#                     )\n",
    "#             )\n",
    "\n",
    "# b  = sampler.get_chain(flat=True, discard=discard, thin=thin)[:,-1] / sampler.get_chain(flat=True, discard=discard, thin=thin)[:,2]\n",
    "# data = np.column_stack((sampler.get_chain(flat=True, discard=discard, thin=thin), b))\n",
    "# print(data.shape)\n",
    "\n",
    "# figsize=(6,6))\n",
    "\n",
    "# fig.axes[10].hist(roa_prior, bins=30, histtype='step')\n",
    "# fig.axes[10].set_xlim(0)\n",
    "# fig.axes[12].hist(roa_prior, bins=30, histtype='step')\n",
    "# fig.axes[12].set_xlim(0)\n",
    "# fig.axes[-1].hist(cosi_prior, bins=30, histtype='step')\n",
    "\n",
    "            \n",
    "# axes[3].axhline(roa, c=\"#aaaaaa\")\n",
    "# axes[4].axhline(np.cos(np.deg2rad(incl)), c=\"#aaaaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44607f2c07184311b31c4b486685aa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([  4.,  17.,  31.,  70., 129., 162., 258., 278., 313., 374., 361.,\n",
       "        366., 331., 334., 286., 208., 203.,  96.,   2.,   0.,   0.,  68.,\n",
       "        465., 377., 342., 242., 222., 175., 162., 124.]),\n",
       " array([0.40757658, 0.42732029, 0.447064  , 0.46680771, 0.48655143,\n",
       "        0.50629514, 0.52603885, 0.54578256, 0.56552627, 0.58526998,\n",
       "        0.6050137 , 0.62475741, 0.64450112, 0.66424483, 0.68398854,\n",
       "        0.70373226, 0.72347597, 0.74321968, 0.76296339, 0.7827071 ,\n",
       "        0.80245081, 0.82219453, 0.84193824, 0.86168195, 0.88142566,\n",
       "        0.90116937, 0.92091309, 0.9406568 , 0.96040051, 0.98014422,\n",
       "        0.99988793]),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(b, histtype='step', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# index_ml = np.argmax(sampler.get_log_prob(discard=discard, flat=True, thin=thin))\n",
    "# theta_ml = sampler.get_chain(discard=discard, flat=True, thin=thin)[index_ml,:]\n",
    "\n",
    "# theta_ml2 = theta_ml.copy()\n",
    "# # theta_ml2[0] = theta_ml[0]**2 + theta_ml[1]**2\n",
    "# # theta_ml2[1] = np.rad2deg(np.arctan2(theta_ml[0], theta_ml[1]))\n",
    "# # theta_ml2[3] = np.rad2deg(np.arccos(theta_ml[3]))\n",
    "# theta_ml2[-1] = np.rad2deg(np.arccos(theta_ml[-1]))\n",
    "# print(theta_ml2)\n",
    "\n",
    "# phase_f = np.linspace(phase[m23].min(), phase[m23].max(), 100)\n",
    "# relo = model.ReloadedModel(phase[m23], r_1=theta_ml2[2], i_p=theta_ml2[3])\n",
    "# mod = relo(theta_ml2[0], theta_ml2[1], istar, alpha, phase=phase[m23])\n",
    "# mu_avg = relo.mu_avg\n",
    "# mod_f = relo(theta_ml2[0], theta_ml2[1], istar, alpha, phase=phase_f)\n",
    "\n",
    "# res = centre - mod\n",
    "# mod0 = np.mean(centre)\n",
    "# res0 = centre - mod0\n",
    "# print('chisq reduced = {0:.4f}'.format(np.sum((res / centre_err)**2) / (len(centre) - 2)))\n",
    "# print('chisq reduced H0 = {0:.4f}'.format(np.sum((res0 / centre_err)**2) / (len(centre) - 2)))\n",
    "# samples = []\n",
    "# for i in np.random.randint(0,sampler.get_chain(flat=True, discard=discard, thin=thin).shape[0],100):\n",
    "#     _roa = sampler.get_chain(flat=True, discard=discard, thin=thin)[i,2]\n",
    "#     _cosi = sampler.get_chain(flat=True, discard=discard, thin=thin)[i,3]\n",
    "#     _incl = np.rad2deg(np.arccos(_cosi))\n",
    "#     _b  = _cosi / _roa\n",
    "# #     reloaded_kwargs_tmp = {'r_1':r_1_mean, 'i_p':incl_mean, 'r_p':k, 'ld':'quad', 'ldc':[0.28, 0.27], 'Nxy':51}\n",
    "#     reloaded_kwargs_tmp = {'r_1':_roa,\n",
    "#                            'i_p':_incl,\n",
    "#                            'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "#     dur23 = utils.get_23_transit_duration(period, _roa, ror, _b, np.deg2rad(_incl))\n",
    "# #     dur14 = utils.get_14_transit_duration(period, roa, ror, b, np.deg2rad(incl_step))\n",
    "#     m = utils.get_transit_mask(phase_in, dur23/period)\n",
    "#     print(m)\n",
    "#     relo = model.ReloadedModel(phase_in[m], **reloaded_kwargs_tmp)\n",
    "#     _mod = relo(sampler.get_chain(flat=True, discard=discard, thin=thin)[i,0],\n",
    "#                         sampler.get_chain(flat=True, discard=discard, thin=thin)[i,1],\n",
    "#                         90, 0, phase=phase_f)\n",
    "# #     print(_mod)\n",
    "#     samples.append(_mod)\n",
    "# samples = np.atleast_2d(samples)\n",
    "\n",
    "# # samples = np.atleast_2d([relo(fc_convert[i,0], fc_convert[i,1], 90, 0, phase=phase_f) for i in np.random.randint(0,fc.shape[0],100)])\n",
    "# # samples = np.atleast_2d([relo(fc_convert[i,0], fc_convert[i,1], 90, 0, phase=phase_f, r_1=fc_convert[i,2], i_p=fc_convert[i,3]) for i in np.random.randint(0,fc.shape[0],100)])\n",
    "# # fig = utils.plot_fit(phase[m], rv[m], np.sqrt(rv_err[m]**2 + theta_ml[-1]**2), res, phase_f, mod_f, period=P)#, z=mu_avg)\n",
    "# fig = utils.plot_fit(phase[m23], centre, centre_err, res, phase_f, mod_f, period=period, samples=samples, ylim=[-4,4])#, z=mu_avg)\n",
    "# # fig.axes[0].plot(phase_f*P*24, relo(3.6, 0., 90., 0., phase=phase_f))\n",
    "# # fig.axes[0].plot(phase_f*24, relo(3.6, 0., 90., 0., phase=phase_f))\n",
    "# # fig.axes[0].axvline(-0.5*dur14*24, c='#aaaaaa')\n",
    "# # fig.axes[0].axvline(-0.5*dur23*24, c='#aaaaaa', ls='dashed')\n",
    "# # fig.axes[0].axvline(0.5*dur23*24, c='#aaaaaa', ls='dashed')\n",
    "# # fig.axes[0].axvline(0.5*dur14*24, c='#aaaaaa')\n",
    "# # fig.axes[1].set_ylim(-3, 3)\n",
    "# print(istar, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.26532976 -0.44217832]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf6ebc5f1244004acaa854443ca918b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.311034;0.775x0.568966)\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "index_ml = np.argmax(sampler.get_log_prob(discard=discard, thin=thin, flat=True))\n",
    "\n",
    "# theta_ml = [x[index_ml] for x in posterior_2d.T]\n",
    "theta_ml = posterior_2d[index_ml]\n",
    "print(theta_ml)\n",
    "\n",
    "\n",
    "phase_f = np.linspace(-0.5 * dur14/period, 0.5 * dur14/period, 200)\n",
    "# phase_f = np.linspace(-0.01, 0.01, 200)\n",
    "# phase_f = np.linspace(phase[0], phase[-1], 100)\n",
    "\n",
    "# reloaded_kwargs = {'r_1':theta_ml[], 'i_p':theta_ml[3], 'r_p':k, 'ld':'quad', 'ldc':[0.28,  0.27], 'Nxy':51}\n",
    "#                   'oversample':3, 'dp':900/60/60/24/P}\n",
    "\n",
    "reloaded_kwargs = {'r_1':roa, 'i_p':incl, 'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "relo = model.ReloadedModel(phase_in, **reloaded_kwargs)\n",
    "\n",
    "# ymod1 = relo(theta_ml[0], theta_ml[1], istar, alpha, phase=phase1[m1])\n",
    "# ymod2  = relo(theta_ml[0], theta_ml[1], istar, alpha, phase=phase2[m2])\n",
    "mod = relo(theta_ml[0], theta_ml[1], istar, alpha)#, phase=phase_in)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mu_avg = relo.mu_avg\n",
    "# mod_f = relo(theta_ml[0], theta_ml[1], istar, alpha, phase=phase_f)\n",
    "mod_f = relo(*theta_ml, istar, alpha, phase=phase_f)\n",
    "\n",
    "# mod0_f = relo(theta_ml[0], 0, istar, alpha, phase=phase_f)\n",
    "# mod90_f = relo(theta_ml[0], -90, istar, alpha, phase=phase_f)\n",
    "# mod180_f = relo(theta_ml[0], 180, istar, alpha, phase=phase_f)\n",
    "\n",
    "\n",
    "# print(6.2 * np.sin(np.deg2rad(120)) * (1 - 0.5*np.sin(np.deg2rad(45))**2))\n",
    "\n",
    "# omc = centre - mod\n",
    "# omc1 = rv1[m1] - ymod1\n",
    "# omc2 = rv2[m2] - ymod2\n",
    "\n",
    "    \n",
    "# samples = np.atleast_2d([relo(chain3[i,0], chain3[i,1], istar, alpha,\n",
    "#                                   r_1=r_1_mean, i_p=incl_mean, phase=phase_f)\n",
    "#                              for i in np.random.randint(0,vsini.shape[0],100)])\n",
    "\n",
    "samples = np.atleast_2d([relo(*posterior_2d[i], istar, alpha, phase=phase_f)\n",
    "                         for i in np.random.randint(0,posterior_2d.shape[0],100)])\n",
    "# mod_f = np.median(samples, axis=0)\n",
    "# print(what)\n",
    "\n",
    "# reloaded_kwargs = {'r_1':r_1, 'i_p':incl, 'r_p':k, 'ld':'power2', 'ldc':[c, alpha], 'Nxy':51}\n",
    "\n",
    "# relo = model.ReloadedModel(phase[converged], **reloaded_kwargs)\n",
    "# ynormmark = relo.y_norm_mark(np.deg2rad(45), np.deg2rad(100))[0,25,25]\n",
    "# latitudes = [np.rad2deg(np.arcsin(x[25,25])) for x in relo.y_norm_mark(np.deg2rad(45), np.deg2rad(90))]\n",
    "# print(latitudes)\n",
    "# print(ynormmark)\n",
    "# print(6.2 * np.sin(np.deg2rad(100)) * (1 - 0.5 * ynormmark**2))\n",
    "# print(samples)\n",
    "\n",
    "# period = P\n",
    "\n",
    "# xf = phase_f\n",
    "# x = phase[m]\n",
    "# y = rv[m]\n",
    "# yerr = rv_err[m]\n",
    "\n",
    "# x = [phase1[m1], phase2[m2]]\n",
    "# y = [rv_fit1[m1], rv_fit2[m2]]\n",
    "# yerr = [rv_err_fit1[m1], rv_err_fit2[m2]]\n",
    "\n",
    "\n",
    "# if isinstance(x, np.ndarray):\n",
    "#     x = [x]\n",
    "# if isinstance(y, np.ndarray):\n",
    "#     y = [y]\n",
    "# if isinstance(yerr, np.ndarray):\n",
    "#     yerr = [yerr]\n",
    "# if isinstance(omc, np.ndarray):\n",
    "#     omc = [omc]\n",
    "# if isinstance(omc_d, np.ndarray):\n",
    "#     omc_d = [omc_d]\n",
    "\n",
    "\n",
    "# n = len(x)\n",
    "\n",
    "\n",
    "# if samples is not None:\n",
    "#     samples = np.atleast_2d(samples)\n",
    "\n",
    "    \n",
    "plt.style.use('default')\n",
    "# figsize = [None, 3]\n",
    "# fs = [5, 4.42]\n",
    "# figsize=None\n",
    "# if figsize is None:\n",
    "#     fs = figsize\n",
    "# elif None in figsize:\n",
    "\n",
    "#     fig    = plt.figure()\n",
    "#     w, h   = figsize\n",
    "#     _w, _h = fig.get_size_inches()\n",
    "\n",
    "#     w = _w if w is None else w\n",
    "#     h = _h if h is None else h\n",
    "\n",
    "#     fs = (w, h)\n",
    "\n",
    "ncols = 1\n",
    "gridspec_kw = {\n",
    "              'height_ratios':[3,1], \n",
    "              'hspace':0.03,\n",
    "              'wspace':0.02\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "# gs = GridSpec(2, ncols, **gridspec_kw)\n",
    "# fig = plt.figure(figsize=fs) # if twocol\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, gridspec_kw=gridspec_kw)\n",
    "# fig = plt.subplots(2, 1, gridspec_kw=gridspec_kw, squeeze=True)\n",
    "print(ax1)\n",
    "print(fig)\n",
    "# fig = plt.figure()\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0,0])\n",
    "# ax2 = fig.add_subplot(gs[1,0], sharex=ax1)\n",
    "# ax3 = fig.add_subplot(gs[0,1], sharey=ax1)\n",
    "# ax4 = fig.add_subplot(gs[1,1], sharex=ax3, sharey=ax2)\n",
    "\n",
    "\n",
    "ax1.set_ylabel('stellar surface velocity (km/s)')\n",
    "ax1.tick_params(axis='x', which='both', labelbottom=False)\n",
    "# ax3.tick_params(axis='both', which='both', labelbottom=False, labelleft=False)\n",
    "# ax4.tick_params(axis='y', which='both', labelleft=False)\n",
    "\n",
    "c1, c2, c3, c4 = 0.5 / period * np.array([-dur14, -dur23, dur23, dur14])\n",
    "\n",
    "\n",
    "# 14.608559\n",
    "ax1.axvline(c1, c='#aaaaaa', lw=1, ls='solid')\n",
    "ax1.axvline(c2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "ax1.axvline(c3, c='#aaaaaa', lw=1, ls='dotted')\n",
    "ax1.axvline(c4, c='#aaaaaa', lw=1, ls='solid')\n",
    "\n",
    "# ax2.axvline(-W14*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax2.axvline(-W23*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax2.axvline(W23*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax2.axvline(W14*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "\n",
    "# ax3.axvline(-W14*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax3.axvline(-W23*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax3.axvline(W23*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax3.axvline(W14*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "\n",
    "# ax4.axvline(-W14*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax4.axvline(-W23*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax4.axvline(W23*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "# ax4.axvline(W14*24/2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "\n",
    "# if ylim is None:\n",
    "offset = np.median(centre_err)\n",
    "ylim = (mod.min()-offset, mod.max()+offset)\n",
    "ax1.set_ylim(ylim)\n",
    "\n",
    "\n",
    "# offset = np.median(yerr)\n",
    "# ylim = (ymod.min()-offset, ymod.max()+offset)\n",
    "# ax1.set_ylim(ylim)\n",
    "# ax1.set_xlim(xf[0]*P*24, xf[-1]*P*24)\n",
    "\n",
    "\n",
    "ax2.tick_params(axis='x', which='both', top=True)\n",
    "# ax4.tick_params(axis='x', which='both', top=True)\n",
    "xlabel = 'phase'\n",
    "# if period is not None:\n",
    "#     xlabel += ' (hours)'\n",
    "    \n",
    "ax2.set_ylabel('O - C')\n",
    "\n",
    "ax2.set_xlabel(xlabel)\n",
    "# ax4.set_xlabel(xlabel)\n",
    "\n",
    "# residuals\n",
    "# ax2.set_ylim(-5*np.median(centre_err), 5*np.median(centre_err))\n",
    "\n",
    "markers = ['.', 's']\n",
    "# \n",
    "colors = ['k', 'C1']\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {'capsize':0, 'fmt':'none', 'color':colors[0],\n",
    "            'alpha':1.0, 'elinewidth':1.0}\n",
    "ax1.errorbar(phase_in, centre, yerr=centre_err, **kwargs)\n",
    "ax2.errorbar(phase_in, centre - mod, yerr=centre_err,\n",
    "        **kwargs)\n",
    "\n",
    "# kwargs = {'capsize':0, 'fmt':'none', 'color':colors[0],\n",
    "#             'alpha':1.0, 'elinewidth':1.0}\n",
    "# ax1.errorbar(phase1[m1]*period*24, rv1[m1], yerr=rv_err1[m1], **kwargs)\n",
    "# ax2.errorbar(phase1[m1]*period*24, omc1, yerr=rv_err1[m1],\n",
    "#         **kwargs)\n",
    "\n",
    "\n",
    "kwargs = {'fmt':markers[0], 'color':colors[0], 'ms':10}\n",
    "ax1.errorbar(phase_in, centre, **kwargs)\n",
    "ax2.errorbar(phase_in, centre - mod, **kwargs)\n",
    "\n",
    "\n",
    "# kwargs = {'fmt':markers[0], 'color':'white', 'ms':7.8, 'mew':0}\n",
    "# ax1.errorbar(phase1[m1]*period*24, rv1[m1], **kwargs)\n",
    "# ax2.errorbar(phase1[m1]*period*24, omc1, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# kwargs = {'capsize':0, 'fmt':'none', 'color':colors[1],\n",
    "#             'alpha':1.0, 'elinewidth':1.0, 'zorder':-100}\n",
    "# ax1.errorbar(phase2[m2]*period*24, rv2[m2], yerr=rv_err2[m2], **kwargs)\n",
    "# ax2.errorbar(phase2[m2]*period*24, omc2, yerr=rv_err2[m2],\n",
    "#         **kwargs)\n",
    "\n",
    "\n",
    "# kwargs = {'fmt':markers[1], 'color':colors[1], 'ms':4.5, 'zorder':-100}\n",
    "# ax1.errorbar(phase2[m2]*period*24, rv2[m2], label='B', **kwargs)\n",
    "# ax2.errorbar(phase2[m2]*period*24, omc2, **kwargs)\n",
    "# ax1.legend(loc='upper left')\n",
    "\n",
    "# kwargs = {'fmt':markers[1], 'color':'white', 'ms':3.5, 'mew':0, 'zorder':-100}\n",
    "# ax1.errorbar(phase2[m2]*period*24, rv2[m2], **kwargs)\n",
    "# ax2.errorbar(phase2[m2]*period*24, omc2, **kwargs)\n",
    "    \n",
    "    \n",
    "\n",
    "ax2.axhline(0, c=\"#aaaaaa\", lw=1)\n",
    "\n",
    "ax1.set_xlim(c1, c4)\n",
    "ax2.set_xlim(c1, c4)\n",
    "\n",
    "ax1.set_ylim(-3, 3)\n",
    "# ax2.set_ylim(-0.2, 0.2)\n",
    "\n",
    "\n",
    "# ax1.plot(phase_f, mod_f, color='#aaaaaa', lw=0.5, zorder=-150)\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "\n",
    "percs = np.linspace(51, 99, 100)\n",
    "\n",
    "colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))\n",
    "\n",
    "for i, p in enumerate(percs[::-1]):\n",
    "    upper = np.percentile(samples, p, axis=0)\n",
    "    lower = np.percentile(samples, 100-p, axis=0)\n",
    "    color_val = colors[i]\n",
    "    ax1.fill_between(phase_f, upper, lower, color=cmap(color_val), alpha=0.8, zorder=-200)#, **fill_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([900.0011, 900.0017, 900.0012, 600.0021, 600.0015, 600.0028,\n",
       "       600.0024, 600.0019, 600.0014, 600.0002, 600.0015, 600.0009,\n",
       "       600.0008, 600.0015, 599.9999, 600.0007, 600.0014, 600.0007,\n",
       "       599.9998, 600.0005])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texp * 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [18:38<00:00,  8.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import emcee\n",
    "sys.path.append(\"/Users/vxh710/PhD/software/elle\")\n",
    "import model\n",
    "\n",
    "\n",
    "threads = 2\n",
    "walkers = 400\n",
    "steps = 10000\n",
    "\n",
    "bounds = ((-5, 5), (-5, 5), (-1, 1), (0, 1))\n",
    "\n",
    "reloaded_kwargs = {'r_1':roa, 'i_p':incl, 'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "#                   'oversample':5, 'dp':600/60/60/24/period}\n",
    "\n",
    "relo = model.ReloadedModel(phase_in, **reloaded_kwargs)\n",
    "\n",
    "def _log_prior(theta):\n",
    "        \n",
    "    vs, vc, cosi, alpha = theta\n",
    "    \n",
    "    if vs < bounds[0][0] or vs > bounds[0][1]:\n",
    "        return -np.inf\n",
    "    elif vc < bounds[1][0] or vc > bounds[1][1]:\n",
    "        return -np.inf\n",
    "    elif cosi < bounds[2][0] or cosi > bounds[2][1]:\n",
    "        return -np.inf\n",
    "    elif alpha < bounds[3][0] or alpha > bounds[3][1]:\n",
    "        return -np.inf\n",
    "\n",
    "    return 0\n",
    "\n",
    "def _log_likelihood(data, model, error):\n",
    "        inv_sigma2 = 1/error**2\n",
    "        return -0.5 * np.sum((data - model)**2 * inv_sigma2 - np.log(inv_sigma2))\n",
    "\n",
    "def _log_probability(theta):\n",
    "\n",
    "    # calculate prior and check the new parameters are within bounds\n",
    "    l = _log_prior(theta)\n",
    "    \n",
    "    if not np.isfinite(l):\n",
    "        return -np.inf\n",
    "    \n",
    "    # calculate vsini and lambda from the free parameters\n",
    "    vs, vc, cosi, alpha = theta # vs = sqrt(vsini) * np.sin(lambda); vc = sqrt(vsini) * np.cos(lambda)\n",
    "    veq = vs**2 + vc**2  \n",
    "    ell = np.rad2deg(np.arctan2(vs, vc))\n",
    "    istar = np.rad2deg(np.arccos(cosi))\n",
    "\n",
    "    mod = relo(veq, ell, istar, alpha) # calculate surface RV model\n",
    "\n",
    "    l += _log_likelihood(centre, mod, centre_err)\n",
    "    \n",
    "    return l\n",
    "\n",
    "parameters = ['vs', 'vc', 'cosi', 'alpha']\n",
    "ndim = len(parameters)\n",
    "\n",
    "init = []\n",
    "for i in range(walkers):\n",
    "    pos = [np.random.uniform(*bound) for bound in bounds]\n",
    "    \n",
    "    # check that the initial positions are within prior bounds to be safe\n",
    "    while not np.isfinite(_log_prior(pos)):\n",
    "        pos = [np.random.uniform(*bound) for bound in bounds]\n",
    "\n",
    "    init.append(pos)\n",
    "\n",
    "    \n",
    "if threads > 1:\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    with Pool(processes=threads) as pool:\n",
    "        sampler = emcee.EnsembleSampler(walkers, ndim,\n",
    "                                        _log_probability,\n",
    "                                        pool=pool)\n",
    "#                                         args=(phase, rv, rv_err))\n",
    "        sampler.run_mcmc(init, steps, progress=True)\n",
    "else:\n",
    "    sampler = emcee.EnsembleSampler(walkers, ndim,\n",
    "                                        _log_probability)\n",
    "#                                         args=(phase, rv, rv_err))\n",
    "    sampler.run_mcmc(init, steps, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AutocorrError",
     "evalue": "The chain is shorter than 50 times the integrated autocorrelation time for 4 parameter(s). Use this estimate with caution and run a longer chain!\nN/50 = 100;\ntau: [145.33193711 318.31650407 341.36206497 257.97477934]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAutocorrError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-0f7f3227c48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocorr_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36mget_autocorr_time\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_autocorr_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocorr_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mget_autocorr_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocorr_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/emcee/backends/backend.py\u001b[0m in \u001b[0;36mget_autocorr_time\u001b[0;34m(self, discard, thin, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m    149\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mthin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mautocorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrated_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/emcee/autocorr.py\u001b[0m in \u001b[0;36mintegrated_time\u001b[0;34m(x, c, tol, quiet)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"N/{0} = {1:.0f};\\ntau: {2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAutocorrError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAutocorrError\u001b[0m: The chain is shorter than 50 times the integrated autocorrelation time for 4 parameter(s). Use this estimate with caution and run a longer chain!\nN/50 = 100;\ntau: [145.33193711 318.31650407 341.36206497 257.97477934]"
     ]
    }
   ],
   "source": [
    "sampler.get_autocorr_time(discard=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789dc50ea99e4b5f9193c9d1cd1b1991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# discard = int(0.5 * steps)\n",
    "# thin = int(np.mean(sampler.get_autocorr_time(discard=discard)))\n",
    "\n",
    "discard = 5000\n",
    "thin = 300\n",
    "\n",
    "stepsarr = np.arange(int((steps-discard)/thin))\n",
    "\n",
    "fig, axes = plt.subplots(ndim+1,1, figsize=(10,2*ndim),\n",
    "        gridspec_kw={\"hspace\":0.04})\n",
    "\n",
    "\n",
    "vsini = np.sum(sampler.get_chain(discard=discard, thin=thin)[:,:,:2]**2, axis=-1)\n",
    "ell = np.rad2deg(np.arctan2(*np.rollaxis(sampler.get_chain(discard=discard, thin=thin)[:,:,:2], 2, 0)))\n",
    "istar = np.rad2deg(np.arccos(sampler.get_chain(discard=discard, thin=thin)[:,:,2]))\n",
    "posterior_3d = np.dstack((vsini, ell, istar, sampler.get_chain(discard=discard, thin=thin)[:,:,3]))\n",
    "\n",
    "labels = ['logp', r'$v_\\mathrm{eq}$ (km/s)', r'$\\lambda$ (deg)', r'$i_\\star$ (deg)', r'$\\alpha$']\n",
    "\n",
    "for i in range(ndim+1):\n",
    "    axes[i].set_xlim(0, stepsarr.max())\n",
    "    for j in range(walkers):\n",
    "        if i == 0:\n",
    "            axes[i].plot(stepsarr, sampler.get_log_prob(discard=discard, thin=thin)[:,j], lw=0.5)\n",
    "        else:\n",
    "            axes[i].plot(stepsarr, posterior_3d[:,j,i-1], lw=0.5)\n",
    "        axes[i].set_ylabel(labels[i])\n",
    "        if i == ndim:\n",
    "            axes[i].set_xlabel('steps')\n",
    "        else:\n",
    "            axes[i].tick_params(labelbottom=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b388bf533141b99422b471a5641225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import corner\n",
    "\n",
    "# labels = [\"$v\\sin{i}$ (km/s)\", \"$\\lambda$ (deg)\"]\n",
    "\n",
    "posterior_2d = posterior_3d.reshape((-1, posterior_3d.shape[-1]))\n",
    "\n",
    "fig = corner.corner(\n",
    "    posterior_2d,\n",
    "             labels=labels[1:], show_titles=True, title_fmt=\".4f\", bins=30)#,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.12608022 -0.19886369 97.85334224  0.69757022]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113d881a19cb420bbefe0e744cdfcb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_ml = np.argmax(sampler.get_log_prob(discard=discard, thin=thin, flat=True))\n",
    "\n",
    "theta_ml = posterior_2d[index_ml]\n",
    "print(theta_ml)\n",
    "\n",
    "\n",
    "phase_f = np.linspace(-0.5 * dur14/period, 0.5 * dur14/period, 200)\n",
    "\n",
    "\n",
    "reloaded_kwargs = {'r_1':roa, 'i_p':incl, 'r_p':ror, 'ld':'quad', 'ldc':u, 'Nxy':51}\n",
    "relo = model.ReloadedModel(phase_in, **reloaded_kwargs)\n",
    "\n",
    "mod = relo(theta_ml[0], theta_ml[1], theta_ml[2], theta_ml[3])\n",
    "\n",
    "mod_f = relo(*theta_ml, phase=phase_f)\n",
    "\n",
    "\n",
    "samples = np.atleast_2d([relo(*posterior_2d[i], phase=phase_f)\n",
    "                         for i in np.random.randint(0,posterior_2d.shape[0],100)])\n",
    "\n",
    "\n",
    "ncols = 1\n",
    "gridspec_kw = {\n",
    "              'height_ratios':[3,1], \n",
    "              'hspace':0.03,\n",
    "              'wspace':0.02\n",
    "              }\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, gridspec_kw=gridspec_kw)\n",
    "\n",
    "ax1.set_ylabel('stellar surface velocity (km/s)')\n",
    "ax1.tick_params(axis='x', which='both', labelbottom=False)\n",
    "\n",
    "\n",
    "c1, c2, c3, c4 = 0.5 / period * np.array([-dur14, -dur23, dur23, dur14])\n",
    "\n",
    "ax1.axvline(c1, c='#aaaaaa', lw=1, ls='solid')\n",
    "ax1.axvline(c2, c='#aaaaaa', lw=1, ls='dotted')\n",
    "ax1.axvline(c3, c='#aaaaaa', lw=1, ls='dotted')\n",
    "ax1.axvline(c4, c='#aaaaaa', lw=1, ls='solid')\n",
    "\n",
    "offset = np.median(centre_err)\n",
    "ylim = (mod.min()-offset, mod.max()+offset)\n",
    "ax1.set_ylim(ylim)\n",
    "\n",
    "\n",
    "\n",
    "ax2.tick_params(axis='x', which='both', top=True)\n",
    "ax2.set_ylabel('O - C')\n",
    "\n",
    "ax2.set_xlabel('phase')\n",
    "\n",
    "\n",
    "markers = ['.', 's']\n",
    "# \n",
    "colors = ['k', 'C1']\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {'capsize':0, 'fmt':'none', 'color':colors[0],\n",
    "            'alpha':1.0, 'elinewidth':1.0}\n",
    "ax1.errorbar(phase_in, centre, yerr=centre_err, **kwargs)\n",
    "ax2.errorbar(phase_in, centre - mod, yerr=centre_err,\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {'fmt':markers[0], 'color':colors[0], 'ms':10}\n",
    "ax1.errorbar(phase_in, centre, **kwargs)\n",
    "ax2.errorbar(phase_in, centre - mod, **kwargs)\n",
    "    \n",
    "    \n",
    "\n",
    "ax2.axhline(0, c=\"#aaaaaa\", lw=1)\n",
    "\n",
    "ax1.set_xlim(c1, c4)\n",
    "ax2.set_xlim(c1, c4)\n",
    "\n",
    "ax1.set_ylim(-4, 4)\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "\n",
    "percs = np.linspace(51, 99, 100)\n",
    "\n",
    "colors = (percs - np.min(percs)) / (np.max(percs) - np.min(percs))\n",
    "\n",
    "for i, p in enumerate(percs[::-1]):\n",
    "    upper = np.percentile(samples, p, axis=0)\n",
    "    lower = np.percentile(samples, 100-p, axis=0)\n",
    "    color_val = colors[i]\n",
    "    ax1.fill_between(phase_f, upper, lower, color=cmap(color_val), alpha=0.8, zorder=-200)#, **fill_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
